{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "sys.path.append('/atlas/u/swang/software/GitHub/tile2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TileTripletsDataset, GetBands, RandomFlipAndRotate, ClipAndScale, ToFloatTensor, triplet_dataloader\n",
    "from src.tilenet import make_tilenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Download triplets from bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the download link, unzip triplets into the directory /tile2vec/data/triplets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment stuff\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the dataloader for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these arguments to match your directory and desired parameters\n",
    "img_type = 'naip'\n",
    "tile_dir = '/atlas/u/swang/GitHub/tile2vec/data/triplets/'\n",
    "bands = 4\n",
    "augment = True\n",
    "batch_size = 50\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "n_triplets = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader set up complete.\n"
     ]
    }
   ],
   "source": [
    "dataloader = triplet_dataloader(img_type, tile_dir, bands=bands, augment=augment,\n",
    "                                batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                n_triplets=n_triplets, pairs_only=True)\n",
    "print('Dataloader set up complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Set up TileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = bands\n",
    "z_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TileNet set up complete.\n"
     ]
    }
   ],
   "source": [
    "TileNet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "TileNet.train()\n",
    "if cuda: TileNet.cuda()\n",
    "print('TileNet set up complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = optim.Adam(TileNet.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the directory for saving models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/atlas/u/swang/GitHub/tile2net/models/'\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Train model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "results_fn = os.path.join(model_dir, 'results.txt')\n",
    "with open(results_fn, 'w') as file:\n",
    "\n",
    "    print('Begin training.................')\n",
    "    for epoch in range(0, epochs):\n",
    "        (avg_loss, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n",
    "            TileNet, cuda, dataloader, optimizer, epoch+1, margin=margin, l2=l2,\n",
    "            print_every=print_every, t0=t0)\n",
    "\n",
    "        # Plot l_n, l_d, and l_nd if available\n",
    "        if loss_type == 'triplet':\n",
    "            Y = np.vstack((np.array(vis_data['avg_l_ns']),\n",
    "                           np.array(vis_data['avg_l_ds']),\n",
    "                           np.array(vis_data['avg_l_nds']))).T\n",
    "            legend = ['l_n', 'l_d', 'l_nd']\n",
    "        elif loss_type == 'cosine':\n",
    "            Y = np.vstack((np.array(vis_data['avg_l_ns']),\n",
    "                           np.array(vis_data['avg_l_ds']))).T\n",
    "            legend = ['l_n', 'l_d']\n",
    "        vis.line(Y=Y, X=np.array(range(1, epoch+2)), win='losses',\n",
    "            opts={'legend': legend, 'markers': False,\n",
    "            'title': 'Loss components', 'xlabel': 'Epoch',\n",
    "            'ylabel': 'Average loss'})\n",
    "\n",
    "        # RF comparison with PCA\n",
    "        X = embed_dataset(cnn, z_dim, cuda, img_type, tile_dir,\n",
    "            bands=bands, augment=False, batch_size=50,\n",
    "            shuffle=False, num_workers=4, print_every=None,\n",
    "            n_triplets=rf_triplets)\n",
    "        vis_data['avg_z_norms'].append(np.linalg.norm(X, axis=1).mean())\n",
    "        X = np.delete(X, nan_locs, axis=0)\n",
    "        X_tr, X_te, X_tr_pca, X_te_pca, y_tr, y_te = train_test_split(X, X_pca, y, shuffle=True)\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        rf_acc = rf.score(X_te, y_te)\n",
    "        rf_accs['tile2vec'].append(rf_acc)\n",
    "        rf_accs['PCA'].append(rf_accs['PCA'][-1])\n",
    "        Y = np.vstack((np.array(rf_accs['tile2vec']), rf_accs['PCA'])).T\n",
    "        vis.line(Y=Y, X=np.array(range(0, epoch+2)), win='rf',\n",
    "            opts={'legend': ['tile2vec', 'PCA'], 'markers': False,\n",
    "            'title': 'RF comparison on CDL', 'xlabel': 'Epoch',\n",
    "            'ylabel': 'Accuracy'})\n",
    "\n",
    "        print('Writing results for epoch {}'.format(epoch+1))\n",
    "        file.write('{} {} {} {} {}\\n'.format(\n",
    "            avg_loss, avg_l_n, avg_l_d, avg_l_nd, rf_acc))\n",
    "\n",
    "        # Plot average norm for embedding\n",
    "        Y = np.array(vis_data['avg_z_norms'])\n",
    "        vis.line(Y=Y, X=np.array(range(0, epoch+2)), win='z_norm',\n",
    "            opts={'title': 'Average embedding norm', 'xlabel': 'Epoch',\n",
    "            'ylabel': 'Norm'})\n",
    "\n",
    "        # Plotting PCA of embeddings by CDL class\n",
    "        X_embed_pca = PCA(2).fit_transform(X)\n",
    "        vis.scatter(X=X_embed_pca[:1000], Y=y[:1000], win='pca{}'.format(epoch % 3),\n",
    "            opts={'title': 'Epoch {}: PCA by CDL label'.format(epoch+1),\n",
    "            'xlabel': 'PC 1', 'ylabel': 'PC 2'})\n",
    "\n",
    "        # Plot histograms of latent dimensions\n",
    "        for d_z in range(min(z_dim, 3)):\n",
    "            vis.histogram(X=X[:,d_z], win='z{}'.format(d_z),\n",
    "                opts={'numbins': 20, 'title': 'Epoch {}: Distribution of z{}'.format(epoch+1, d_z)})\n",
    "\n",
    "        # Plot nearest neighbors for embedding and for PCA\n",
    "        n_samples = 5\n",
    "        nrow = 8\n",
    "        k = int(nrow ** 2)\n",
    "        for i in range(n_samples):\n",
    "            samples = np.zeros((k, 3, tile_size, tile_size))\n",
    "            idx = np.random.randint(0, len(tiles))\n",
    "            # Get embedding and PCA neighbors\n",
    "            (topk_idxs, topk_dists) = get_k_neighbors(idx, X, int(k/2))\n",
    "            (topk_idxs_pca, topk_dists_pca) = get_k_neighbors(idx, X_pca, int(k/2))\n",
    "            X_idx = 0\n",
    "            X_pca_idx = 0\n",
    "            for j in range(k):\n",
    "                if j % nrow < nrow / 2:\n",
    "                    topk_idx = topk_idxs[X_idx]\n",
    "                    X_idx += 1\n",
    "                else:\n",
    "                    topk_idx = topk_idxs_pca[X_pca_idx]\n",
    "                    X_pca_idx += 1\n",
    "                samples[j,:,:,:] = np.moveaxis(tiles[topk_idx][:,:,:3], -1, 0)\n",
    "            vis.images(samples, win='knn{}_{}'.format(epoch % 5, i),\n",
    "                opts={'nrow': nrow, 'title': '=== tile2vec (left half) ===== Epoch {}, #{} ===== PCA (right half) =========='.format(epoch+1, i+1)})\n",
    "\n",
    "        # Save model\n",
    "        if save_models:\n",
    "            if rf_acc == np.max(np.array(rf_accs['tile2vec'])) or epoch == epochs-1:\n",
    "                model_fn = os.path.join(model_dir, 'epoch{}.ckpt'.format(epoch+1))\n",
    "                torch.save(cnn.state_dict(), model_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
