{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import TileTripletsDataset, GetBands, RandomFlipAndRotate, ClipAndScale, ToFloatTensor, triplet_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Download triplets from bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the download link, unzip triplets into the directory tile2vec/data/naip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Train TileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment stuff\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the dataloader for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these arguments to match your directory and desired parameters\n",
    "patch_dir = '/atlas/u/nj/GitHub/pixel2vec/data/interim/naip_fresno/triplets50_100/'\n",
    "augment = True\n",
    "batch_size = args.batch_size\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "n_triplets = args.n_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = triplet_dataloader(img_type, patch_dir, bands=bands,\n",
    "    augment=augment, batch_size=batch_size, shuffle=shuffle,\n",
    "    num_workers=num_workers, n_triplets=n_triplets, normalize=normalize)\n",
    "print('Dataloader set up complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = bands\n",
    "supervised = False\n",
    "no_relu = False\n",
    "patch_size = 50\n",
    "n_filters = 50\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'resnet':\n",
    "    cnn = ResNet18(in_channels=in_channels, z_dim=z_dim,\n",
    "        supervised=supervised, no_relu=no_relu, loss_type=loss_type,\n",
    "        activation=activation)\n",
    "elif model == 'cnn':\n",
    "    cnn = CNN(in_channels=in_channels, z_dim=z_dim, patch_size=patch_size,\n",
    "        n_filters=n_filters, kernel_size=kernel_size)\n",
    "cnn.train()\n",
    "if cuda: cnn.cuda()\n",
    "print('CNN set up complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory for saving models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('/atlas/u/nj/GitHub/pixel2vec/models/', env)\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
    "config_fn = os.path.join(model_dir, 'config.yaml')\n",
    "config = vars(args)\n",
    "config['env'] = env\n",
    "if save_models:\n",
    "    with open(config_fn, 'w') as file:\n",
    "        print('Writing config file')\n",
    "        file.write(dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "results_fn = os.path.join(model_dir, 'results.txt')\n",
    "with open(results_fn, 'w') as file:\n",
    "\n",
    "    print('Begin training.................')\n",
    "    for epoch in range(0, epochs):\n",
    "        (avg_loss, avg_l_n, avg_l_d, avg_l_nd) = train_triplet_epoch(\n",
    "            cnn, cuda, dataloader, optimizer, epoch+1, margin=margin, l2=l2,\n",
    "            print_every=print_every, t0=t0)\n",
    "#         vis_data['avg_losses'].append(avg_loss)\n",
    "#         vis_data['avg_l_ns'].append(avg_l_n)\n",
    "#         vis_data['avg_l_ds'].append(avg_l_d)\n",
    "#         vis_data['avg_l_nds'].append(avg_l_nd)\n",
    "\n",
    "        # Plot loss\n",
    "#         Y = np.array(vis_data['avg_losses'])\n",
    "#         vis.line(Y=Y, X=np.array(range(1, epoch+2)), win='loss',\n",
    "#             opts={'legend': ['loss'], 'markers': False,\n",
    "#             'title': 'Training loss',\n",
    "#             'xlabel': 'Epoch', 'ylabel': 'Average loss'})\n",
    "\n",
    "        # Plot l_n, l_d, and l_nd if available\n",
    "        if loss_type == 'triplet':\n",
    "            Y = np.vstack((np.array(vis_data['avg_l_ns']),\n",
    "                           np.array(vis_data['avg_l_ds']),\n",
    "                           np.array(vis_data['avg_l_nds']))).T\n",
    "            legend = ['l_n', 'l_d', 'l_nd']\n",
    "        elif loss_type == 'cosine':\n",
    "            Y = np.vstack((np.array(vis_data['avg_l_ns']),\n",
    "                           np.array(vis_data['avg_l_ds']))).T\n",
    "            legend = ['l_n', 'l_d']\n",
    "        vis.line(Y=Y, X=np.array(range(1, epoch+2)), win='losses',\n",
    "            opts={'legend': legend, 'markers': False,\n",
    "            'title': 'Loss components', 'xlabel': 'Epoch',\n",
    "            'ylabel': 'Average loss'})\n",
    "\n",
    "        # RF comparison with PCA\n",
    "        X = embed_dataset(cnn, z_dim, cuda, img_type, patch_dir,\n",
    "            bands=bands, augment=False, batch_size=50,\n",
    "            shuffle=False, num_workers=4, print_every=None,\n",
    "            n_triplets=rf_triplets)\n",
    "        vis_data['avg_z_norms'].append(np.linalg.norm(X, axis=1).mean())\n",
    "        X = np.delete(X, nan_locs, axis=0)\n",
    "        X_tr, X_te, X_tr_pca, X_te_pca, y_tr, y_te = train_test_split(X, X_pca, y, shuffle=True)\n",
    "        rf = RandomForestClassifier()\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        rf_acc = rf.score(X_te, y_te)\n",
    "        rf_accs['patch2vec'].append(rf_acc)\n",
    "        rf_accs['PCA'].append(rf_accs['PCA'][-1])\n",
    "        Y = np.vstack((np.array(rf_accs['patch2vec']), rf_accs['PCA'])).T\n",
    "        vis.line(Y=Y, X=np.array(range(0, epoch+2)), win='rf',\n",
    "            opts={'legend': ['patch2vec', 'PCA'], 'markers': False,\n",
    "            'title': 'RF comparison on CDL', 'xlabel': 'Epoch',\n",
    "            'ylabel': 'Accuracy'})\n",
    "\n",
    "        print('Writing results for epoch {}'.format(epoch+1))\n",
    "        file.write('{} {} {} {} {}\\n'.format(\n",
    "            avg_loss, avg_l_n, avg_l_d, avg_l_nd, rf_acc))\n",
    "\n",
    "        # Plot average norm for embedding\n",
    "        Y = np.array(vis_data['avg_z_norms'])\n",
    "        vis.line(Y=Y, X=np.array(range(0, epoch+2)), win='z_norm',\n",
    "            opts={'title': 'Average embedding norm', 'xlabel': 'Epoch',\n",
    "            'ylabel': 'Norm'})\n",
    "\n",
    "        # Plotting PCA of embeddings by CDL class\n",
    "        X_embed_pca = PCA(2).fit_transform(X)\n",
    "        vis.scatter(X=X_embed_pca[:1000], Y=y[:1000], win='pca{}'.format(epoch % 3),\n",
    "            opts={'title': 'Epoch {}: PCA by CDL label'.format(epoch+1),\n",
    "            'xlabel': 'PC 1', 'ylabel': 'PC 2'})\n",
    "\n",
    "        # Plot histograms of latent dimensions\n",
    "        for d_z in range(min(z_dim, 3)):\n",
    "            vis.histogram(X=X[:,d_z], win='z{}'.format(d_z),\n",
    "                opts={'numbins': 20, 'title': 'Epoch {}: Distribution of z{}'.format(epoch+1, d_z)})\n",
    "\n",
    "        # Plot nearest neighbors for embedding and for PCA\n",
    "        n_samples = 5\n",
    "        nrow = 8\n",
    "        k = int(nrow ** 2)\n",
    "        for i in range(n_samples):\n",
    "            samples = np.zeros((k, 3, patch_size, patch_size))\n",
    "            idx = np.random.randint(0, len(patches))\n",
    "            # Get embedding and PCA neighbors\n",
    "            (topk_idxs, topk_dists) = get_k_neighbors(idx, X, int(k/2))\n",
    "            (topk_idxs_pca, topk_dists_pca) = get_k_neighbors(idx, X_pca, int(k/2))\n",
    "            X_idx = 0\n",
    "            X_pca_idx = 0\n",
    "            for j in range(k):\n",
    "                if j % nrow < nrow / 2:\n",
    "                    topk_idx = topk_idxs[X_idx]\n",
    "                    X_idx += 1\n",
    "                else:\n",
    "                    topk_idx = topk_idxs_pca[X_pca_idx]\n",
    "                    X_pca_idx += 1\n",
    "                samples[j,:,:,:] = np.moveaxis(patches[topk_idx][:,:,:3], -1, 0)\n",
    "            vis.images(samples, win='knn{}_{}'.format(epoch % 5, i),\n",
    "                opts={'nrow': nrow, 'title': '=== patch2vec (left half) ===== Epoch {}, #{} ===== PCA (right half) =========='.format(epoch+1, i+1)})\n",
    "\n",
    "        # Save model\n",
    "        if save_models:\n",
    "            if rf_acc == np.max(np.array(rf_accs['patch2vec'])) or epoch == epochs-1:\n",
    "                model_fn = os.path.join(model_dir, 'epoch{}.ckpt'.format(epoch+1))\n",
    "                torch.save(cnn.state_dict(), model_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
